{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUL Prediction Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from pickle import load,dump\n",
    "from datetime import date\n",
    "import os\n",
    "\n",
    "# custom modules\n",
    "from method import compute_eval_matrices\n",
    "from watercan import GroupWaterCan\n",
    "from visualization import make_rul_video \n",
    "from helpers import get_from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name='N-CMAPSS' #'uav_data'#\n",
    "threshold_name=''#'-0.1' #  '+0.1' #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HPT_eff', 'HPT_eff', 'HPT_eff', 'HPT_eff']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(f'./data/{dataset_name}/performs_info.pkl', 'rb') as file:\n",
    "    performs_info=load(file)\n",
    "\n",
    "with open(f'./data/{dataset_name}/time_info.pkl', 'rb') as file:\n",
    "    time_info=load(file)\n",
    "    \n",
    "with open(f'./data/{dataset_name}/times_test{threshold_name}.pkl', 'rb') as file:\n",
    "    t_observ = load(file)\n",
    "\n",
    "with open(f'./data/{dataset_name}/times_test{threshold_name}_threshold.pkl', 'rb') as file:\n",
    "    times_thresholds = load(file)\n",
    "\n",
    "with open(f'./data/{dataset_name}/RUL_test{threshold_name}.pkl', 'rb') as file:\n",
    "    rul= load(file)\n",
    "\n",
    "with open(f'./data/{dataset_name}/EOLcause_test{threshold_name}.pkl', 'rb') as file:\n",
    "    EOLcause= load(file)\n",
    "\n",
    "performs = {}\n",
    "thresholds = {}\n",
    "for name in performs_info.keys():\n",
    "    with open(f'./data/{dataset_name}/{name}_test{threshold_name}.pkl', 'rb') as file:\n",
    "        performs[name] = load(file)\n",
    "    with open(f'./data/{dataset_name}/{name}_test{threshold_name}_threshold.pkl', 'rb') as file:\n",
    "        thresholds[name]= load(file)\n",
    "\n",
    "EOLcause"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "library_address=f'./Library/MTL_2024-08-14_{dataset_name}/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Group Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for GroupWaterCan:\n\tMissing key(s) in state_dict: \"watercans.0.latentf.no_linear.0.0.weight\", \"watercans.0.latentf.no_linear.0.0.bias\", \"watercans.0.latentf.no_linear.1.0.weight\", \"watercans.0.latentf.no_linear.1.0.bias\", \"watercans.0.latentf.linear.0.weight\", \"watercans.0.latentf.linear.0.bias\", \"watercans.0.latentf.linear.1.weight\", \"watercans.0.latentf.linear.1.bias\", \"watercans.0.latentf_out.no_linear.0.0.weight\", \"watercans.0.latentf_out.no_linear.0.0.bias\", \"watercans.0.latentf_out.no_linear.1.0.weight\", \"watercans.0.latentf_out.no_linear.1.0.bias\", \"watercans.0.latentf_out.linear.0.weight\", \"watercans.0.latentf_out.linear.0.bias\", \"watercans.0.latentf_out.linear.1.weight\", \"watercans.0.latentf_out.linear.1.bias\", \"watercans.1.latentf.no_linear.0.0.weight\", \"watercans.1.latentf.no_linear.0.0.bias\", \"watercans.1.latentf.no_linear.1.0.weight\", \"watercans.1.latentf.no_linear.1.0.bias\", \"watercans.1.latentf.linear.0.weight\", \"watercans.1.latentf.linear.0.bias\", \"watercans.1.latentf.linear.1.weight\", \"watercans.1.latentf.linear.1.bias\", \"watercans.1.latentf_out.no_linear.0.0.weight\", \"watercans.1.latentf_out.no_linear.0.0.bias\", \"watercans.1.latentf_out.no_linear.1.0.weight\", \"watercans.1.latentf_out.no_linear.1.0.bias\", \"watercans.1.latentf_out.linear.0.weight\", \"watercans.1.latentf_out.linear.0.bias\", \"watercans.1.latentf_out.linear.1.weight\", \"watercans.1.latentf_out.linear.1.bias\", \"watercans.2.latentf.no_linear.0.0.weight\", \"watercans.2.latentf.no_linear.0.0.bias\", \"watercans.2.latentf.no_linear.1.0.weight\", \"watercans.2.latentf.no_linear.1.0.bias\", \"watercans.2.latentf.linear.0.weight\", \"watercans.2.latentf.linear.0.bias\", \"watercans.2.latentf.linear.1.weight\", \"watercans.2.latentf.linear.1.bias\", \"watercans.2.latentf_out.no_linear.0.0.weight\", \"watercans.2.latentf_out.no_linear.0.0.bias\", \"watercans.2.latentf_out.no_linear.1.0.weight\", \"watercans.2.latentf_out.no_linear.1.0.bias\", \"watercans.2.latentf_out.linear.0.weight\", \"watercans.2.latentf_out.linear.0.bias\", \"watercans.2.latentf_out.linear.1.weight\", \"watercans.2.latentf_out.linear.1.bias\", \"watercans.3.latentf.no_linear.0.0.weight\", \"watercans.3.latentf.no_linear.0.0.bias\", \"watercans.3.latentf.no_linear.1.0.weight\", \"watercans.3.latentf.no_linear.1.0.bias\", \"watercans.3.latentf.linear.0.weight\", \"watercans.3.latentf.linear.0.bias\", \"watercans.3.latentf.linear.1.weight\", \"watercans.3.latentf.linear.1.bias\", \"watercans.3.latentf_out.no_linear.0.0.weight\", \"watercans.3.latentf_out.no_linear.0.0.bias\", \"watercans.3.latentf_out.no_linear.1.0.weight\", \"watercans.3.latentf_out.no_linear.1.0.bias\", \"watercans.3.latentf_out.linear.0.weight\", \"watercans.3.latentf_out.linear.0.bias\", \"watercans.3.latentf_out.linear.1.weight\", \"watercans.3.latentf_out.linear.1.bias\", \"watercans.4.latentf.no_linear.0.0.weight\", \"watercans.4.latentf.no_linear.0.0.bias\", \"watercans.4.latentf.no_linear.1.0.weight\", \"watercans.4.latentf.no_linear.1.0.bias\", \"watercans.4.latentf.linear.0.weight\", \"watercans.4.latentf.linear.0.bias\", \"watercans.4.latentf.linear.1.weight\", \"watercans.4.latentf.linear.1.bias\", \"watercans.4.latentf_out.no_linear.0.0.weight\", \"watercans.4.latentf_out.no_linear.0.0.bias\", \"watercans.4.latentf_out.no_linear.1.0.weight\", \"watercans.4.latentf_out.no_linear.1.0.bias\", \"watercans.4.latentf_out.linear.0.weight\", \"watercans.4.latentf_out.linear.0.bias\", \"watercans.4.latentf_out.linear.1.weight\", \"watercans.4.latentf_out.linear.1.bias\". \n\tUnexpected key(s) in state_dict: \"watercans.0.latentf.backbone.1.weight\", \"watercans.0.latentf.backbone.1.bias\", \"watercans.0.latentf.backbone.2.weight\", \"watercans.0.latentf.backbone.2.bias\", \"watercans.0.latentf.skip.0.weight\", \"watercans.0.latentf.skip.0.bias\", \"watercans.0.latentf.skip.1.weight\", \"watercans.0.latentf.skip.1.bias\", \"watercans.0.latentf.linear_output.weight\", \"watercans.0.latentf.linear_output.bias\", \"watercans.0.latentf_out.backbone.1.weight\", \"watercans.0.latentf_out.backbone.1.bias\", \"watercans.0.latentf_out.backbone.2.weight\", \"watercans.0.latentf_out.backbone.2.bias\", \"watercans.0.latentf_out.skip.0.weight\", \"watercans.0.latentf_out.skip.0.bias\", \"watercans.0.latentf_out.skip.1.weight\", \"watercans.0.latentf_out.skip.1.bias\", \"watercans.0.latentf_out.linear_output.weight\", \"watercans.0.latentf_out.linear_output.bias\", \"watercans.1.latentf.backbone.1.weight\", \"watercans.1.latentf.backbone.1.bias\", \"watercans.1.latentf.backbone.2.weight\", \"watercans.1.latentf.backbone.2.bias\", \"watercans.1.latentf.skip.0.weight\", \"watercans.1.latentf.skip.0.bias\", \"watercans.1.latentf.skip.1.weight\", \"watercans.1.latentf.skip.1.bias\", \"watercans.1.latentf.linear_output.weight\", \"watercans.1.latentf.linear_output.bias\", \"watercans.1.latentf_out.backbone.1.weight\", \"watercans.1.latentf_out.backbone.1.bias\", \"watercans.1.latentf_out.backbone.2.weight\", \"watercans.1.latentf_out.backbone.2.bias\", \"watercans.1.latentf_out.skip.0.weight\", \"watercans.1.latentf_out.skip.0.bias\", \"watercans.1.latentf_out.skip.1.weight\", \"watercans.1.latentf_out.skip.1.bias\", \"watercans.1.latentf_out.linear_output.weight\", \"watercans.1.latentf_out.linear_output.bias\", \"watercans.2.latentf.backbone.1.weight\", \"watercans.2.latentf.backbone.1.bias\", \"watercans.2.latentf.backbone.2.weight\", \"watercans.2.latentf.backbone.2.bias\", \"watercans.2.latentf.skip.0.weight\", \"watercans.2.latentf.skip.0.bias\", \"watercans.2.latentf.skip.1.weight\", \"watercans.2.latentf.skip.1.bias\", \"watercans.2.latentf.linear_output.weight\", \"watercans.2.latentf.linear_output.bias\", \"watercans.2.latentf_out.backbone.1.weight\", \"watercans.2.latentf_out.backbone.1.bias\", \"watercans.2.latentf_out.backbone.2.weight\", \"watercans.2.latentf_out.backbone.2.bias\", \"watercans.2.latentf_out.skip.0.weight\", \"watercans.2.latentf_out.skip.0.bias\", \"watercans.2.latentf_out.skip.1.weight\", \"watercans.2.latentf_out.skip.1.bias\", \"watercans.2.latentf_out.linear_output.weight\", \"watercans.2.latentf_out.linear_output.bias\", \"watercans.3.latentf.backbone.1.weight\", \"watercans.3.latentf.backbone.1.bias\", \"watercans.3.latentf.backbone.2.weight\", \"watercans.3.latentf.backbone.2.bias\", \"watercans.3.latentf.skip.0.weight\", \"watercans.3.latentf.skip.0.bias\", \"watercans.3.latentf.skip.1.weight\", \"watercans.3.latentf.skip.1.bias\", \"watercans.3.latentf.linear_output.weight\", \"watercans.3.latentf.linear_output.bias\", \"watercans.3.latentf_out.backbone.1.weight\", \"watercans.3.latentf_out.backbone.1.bias\", \"watercans.3.latentf_out.backbone.2.weight\", \"watercans.3.latentf_out.backbone.2.bias\", \"watercans.3.latentf_out.skip.0.weight\", \"watercans.3.latentf_out.skip.0.bias\", \"watercans.3.latentf_out.skip.1.weight\", \"watercans.3.latentf_out.skip.1.bias\", \"watercans.3.latentf_out.linear_output.weight\", \"watercans.3.latentf_out.linear_output.bias\", \"watercans.4.latentf.backbone.1.weight\", \"watercans.4.latentf.backbone.1.bias\", \"watercans.4.latentf.backbone.2.weight\", \"watercans.4.latentf.backbone.2.bias\", \"watercans.4.latentf.skip.0.weight\", \"watercans.4.latentf.skip.0.bias\", \"watercans.4.latentf.skip.1.weight\", \"watercans.4.latentf.skip.1.bias\", \"watercans.4.latentf.linear_output.weight\", \"watercans.4.latentf.linear_output.bias\", \"watercans.4.latentf_out.backbone.1.weight\", \"watercans.4.latentf_out.backbone.1.bias\", \"watercans.4.latentf_out.backbone.2.weight\", \"watercans.4.latentf_out.backbone.2.bias\", \"watercans.4.latentf_out.skip.0.weight\", \"watercans.4.latentf_out.skip.0.bias\", \"watercans.4.latentf_out.skip.1.weight\", \"watercans.4.latentf_out.skip.1.bias\", \"watercans.4.latentf_out.linear_output.weight\", \"watercans.4.latentf_out.linear_output.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m model_state\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mload(perform_address\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_state.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m model\u001b[38;5;241m=\u001b[39mGroupWaterCan(configs)\n\u001b[0;32m---> 10\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     12\u001b[0m group_distributions[perform_name]\u001b[38;5;241m=\u001b[39mmodel\n",
      "File \u001b[0;32m~/.conda/envs/abel/lib/python3.11/site-packages/torch/nn/modules/module.py:2041\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   2036\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2037\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2038\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(k) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2040\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2041\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2042\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2043\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for GroupWaterCan:\n\tMissing key(s) in state_dict: \"watercans.0.latentf.no_linear.0.0.weight\", \"watercans.0.latentf.no_linear.0.0.bias\", \"watercans.0.latentf.no_linear.1.0.weight\", \"watercans.0.latentf.no_linear.1.0.bias\", \"watercans.0.latentf.linear.0.weight\", \"watercans.0.latentf.linear.0.bias\", \"watercans.0.latentf.linear.1.weight\", \"watercans.0.latentf.linear.1.bias\", \"watercans.0.latentf_out.no_linear.0.0.weight\", \"watercans.0.latentf_out.no_linear.0.0.bias\", \"watercans.0.latentf_out.no_linear.1.0.weight\", \"watercans.0.latentf_out.no_linear.1.0.bias\", \"watercans.0.latentf_out.linear.0.weight\", \"watercans.0.latentf_out.linear.0.bias\", \"watercans.0.latentf_out.linear.1.weight\", \"watercans.0.latentf_out.linear.1.bias\", \"watercans.1.latentf.no_linear.0.0.weight\", \"watercans.1.latentf.no_linear.0.0.bias\", \"watercans.1.latentf.no_linear.1.0.weight\", \"watercans.1.latentf.no_linear.1.0.bias\", \"watercans.1.latentf.linear.0.weight\", \"watercans.1.latentf.linear.0.bias\", \"watercans.1.latentf.linear.1.weight\", \"watercans.1.latentf.linear.1.bias\", \"watercans.1.latentf_out.no_linear.0.0.weight\", \"watercans.1.latentf_out.no_linear.0.0.bias\", \"watercans.1.latentf_out.no_linear.1.0.weight\", \"watercans.1.latentf_out.no_linear.1.0.bias\", \"watercans.1.latentf_out.linear.0.weight\", \"watercans.1.latentf_out.linear.0.bias\", \"watercans.1.latentf_out.linear.1.weight\", \"watercans.1.latentf_out.linear.1.bias\", \"watercans.2.latentf.no_linear.0.0.weight\", \"watercans.2.latentf.no_linear.0.0.bias\", \"watercans.2.latentf.no_linear.1.0.weight\", \"watercans.2.latentf.no_linear.1.0.bias\", \"watercans.2.latentf.linear.0.weight\", \"watercans.2.latentf.linear.0.bias\", \"watercans.2.latentf.linear.1.weight\", \"watercans.2.latentf.linear.1.bias\", \"watercans.2.latentf_out.no_linear.0.0.weight\", \"watercans.2.latentf_out.no_linear.0.0.bias\", \"watercans.2.latentf_out.no_linear.1.0.weight\", \"watercans.2.latentf_out.no_linear.1.0.bias\", \"watercans.2.latentf_out.linear.0.weight\", \"watercans.2.latentf_out.linear.0.bias\", \"watercans.2.latentf_out.linear.1.weight\", \"watercans.2.latentf_out.linear.1.bias\", \"watercans.3.latentf.no_linear.0.0.weight\", \"watercans.3.latentf.no_linear.0.0.bias\", \"watercans.3.latentf.no_linear.1.0.weight\", \"watercans.3.latentf.no_linear.1.0.bias\", \"watercans.3.latentf.linear.0.weight\", \"watercans.3.latentf.linear.0.bias\", \"watercans.3.latentf.linear.1.weight\", \"watercans.3.latentf.linear.1.bias\", \"watercans.3.latentf_out.no_linear.0.0.weight\", \"watercans.3.latentf_out.no_linear.0.0.bias\", \"watercans.3.latentf_out.no_linear.1.0.weight\", \"watercans.3.latentf_out.no_linear.1.0.bias\", \"watercans.3.latentf_out.linear.0.weight\", \"watercans.3.latentf_out.linear.0.bias\", \"watercans.3.latentf_out.linear.1.weight\", \"watercans.3.latentf_out.linear.1.bias\", \"watercans.4.latentf.no_linear.0.0.weight\", \"watercans.4.latentf.no_linear.0.0.bias\", \"watercans.4.latentf.no_linear.1.0.weight\", \"watercans.4.latentf.no_linear.1.0.bias\", \"watercans.4.latentf.linear.0.weight\", \"watercans.4.latentf.linear.0.bias\", \"watercans.4.latentf.linear.1.weight\", \"watercans.4.latentf.linear.1.bias\", \"watercans.4.latentf_out.no_linear.0.0.weight\", \"watercans.4.latentf_out.no_linear.0.0.bias\", \"watercans.4.latentf_out.no_linear.1.0.weight\", \"watercans.4.latentf_out.no_linear.1.0.bias\", \"watercans.4.latentf_out.linear.0.weight\", \"watercans.4.latentf_out.linear.0.bias\", \"watercans.4.latentf_out.linear.1.weight\", \"watercans.4.latentf_out.linear.1.bias\". \n\tUnexpected key(s) in state_dict: \"watercans.0.latentf.backbone.1.weight\", \"watercans.0.latentf.backbone.1.bias\", \"watercans.0.latentf.backbone.2.weight\", \"watercans.0.latentf.backbone.2.bias\", \"watercans.0.latentf.skip.0.weight\", \"watercans.0.latentf.skip.0.bias\", \"watercans.0.latentf.skip.1.weight\", \"watercans.0.latentf.skip.1.bias\", \"watercans.0.latentf.linear_output.weight\", \"watercans.0.latentf.linear_output.bias\", \"watercans.0.latentf_out.backbone.1.weight\", \"watercans.0.latentf_out.backbone.1.bias\", \"watercans.0.latentf_out.backbone.2.weight\", \"watercans.0.latentf_out.backbone.2.bias\", \"watercans.0.latentf_out.skip.0.weight\", \"watercans.0.latentf_out.skip.0.bias\", \"watercans.0.latentf_out.skip.1.weight\", \"watercans.0.latentf_out.skip.1.bias\", \"watercans.0.latentf_out.linear_output.weight\", \"watercans.0.latentf_out.linear_output.bias\", \"watercans.1.latentf.backbone.1.weight\", \"watercans.1.latentf.backbone.1.bias\", \"watercans.1.latentf.backbone.2.weight\", \"watercans.1.latentf.backbone.2.bias\", \"watercans.1.latentf.skip.0.weight\", \"watercans.1.latentf.skip.0.bias\", \"watercans.1.latentf.skip.1.weight\", \"watercans.1.latentf.skip.1.bias\", \"watercans.1.latentf.linear_output.weight\", \"watercans.1.latentf.linear_output.bias\", \"watercans.1.latentf_out.backbone.1.weight\", \"watercans.1.latentf_out.backbone.1.bias\", \"watercans.1.latentf_out.backbone.2.weight\", \"watercans.1.latentf_out.backbone.2.bias\", \"watercans.1.latentf_out.skip.0.weight\", \"watercans.1.latentf_out.skip.0.bias\", \"watercans.1.latentf_out.skip.1.weight\", \"watercans.1.latentf_out.skip.1.bias\", \"watercans.1.latentf_out.linear_output.weight\", \"watercans.1.latentf_out.linear_output.bias\", \"watercans.2.latentf.backbone.1.weight\", \"watercans.2.latentf.backbone.1.bias\", \"watercans.2.latentf.backbone.2.weight\", \"watercans.2.latentf.backbone.2.bias\", \"watercans.2.latentf.skip.0.weight\", \"watercans.2.latentf.skip.0.bias\", \"watercans.2.latentf.skip.1.weight\", \"watercans.2.latentf.skip.1.bias\", \"watercans.2.latentf.linear_output.weight\", \"watercans.2.latentf.linear_output.bias\", \"watercans.2.latentf_out.backbone.1.weight\", \"watercans.2.latentf_out.backbone.1.bias\", \"watercans.2.latentf_out.backbone.2.weight\", \"watercans.2.latentf_out.backbone.2.bias\", \"watercans.2.latentf_out.skip.0.weight\", \"watercans.2.latentf_out.skip.0.bias\", \"watercans.2.latentf_out.skip.1.weight\", \"watercans.2.latentf_out.skip.1.bias\", \"watercans.2.latentf_out.linear_output.weight\", \"watercans.2.latentf_out.linear_output.bias\", \"watercans.3.latentf.backbone.1.weight\", \"watercans.3.latentf.backbone.1.bias\", \"watercans.3.latentf.backbone.2.weight\", \"watercans.3.latentf.backbone.2.bias\", \"watercans.3.latentf.skip.0.weight\", \"watercans.3.latentf.skip.0.bias\", \"watercans.3.latentf.skip.1.weight\", \"watercans.3.latentf.skip.1.bias\", \"watercans.3.latentf.linear_output.weight\", \"watercans.3.latentf.linear_output.bias\", \"watercans.3.latentf_out.backbone.1.weight\", \"watercans.3.latentf_out.backbone.1.bias\", \"watercans.3.latentf_out.backbone.2.weight\", \"watercans.3.latentf_out.backbone.2.bias\", \"watercans.3.latentf_out.skip.0.weight\", \"watercans.3.latentf_out.skip.0.bias\", \"watercans.3.latentf_out.skip.1.weight\", \"watercans.3.latentf_out.skip.1.bias\", \"watercans.3.latentf_out.linear_output.weight\", \"watercans.3.latentf_out.linear_output.bias\", \"watercans.4.latentf.backbone.1.weight\", \"watercans.4.latentf.backbone.1.bias\", \"watercans.4.latentf.backbone.2.weight\", \"watercans.4.latentf.backbone.2.bias\", \"watercans.4.latentf.skip.0.weight\", \"watercans.4.latentf.skip.0.bias\", \"watercans.4.latentf.skip.1.weight\", \"watercans.4.latentf.skip.1.bias\", \"watercans.4.latentf.linear_output.weight\", \"watercans.4.latentf.linear_output.bias\", \"watercans.4.latentf_out.backbone.1.weight\", \"watercans.4.latentf_out.backbone.1.bias\", \"watercans.4.latentf_out.backbone.2.weight\", \"watercans.4.latentf_out.backbone.2.bias\", \"watercans.4.latentf_out.skip.0.weight\", \"watercans.4.latentf_out.skip.0.bias\", \"watercans.4.latentf_out.skip.1.weight\", \"watercans.4.latentf_out.skip.1.bias\", \"watercans.4.latentf_out.linear_output.weight\", \"watercans.4.latentf_out.linear_output.bias\". "
     ]
    }
   ],
   "source": [
    "group_distributions={}\n",
    "for perform_name in performs_info.keys():\n",
    "    perform_info=performs_info[perform_name]\n",
    "\n",
    "    perform_address=library_address+f'{perform_name}/'\n",
    "\n",
    "    configs=torch.load(perform_address+'config.pth')\n",
    "    model_state=torch.load(perform_address+'model_state.pth')\n",
    "    model=GroupWaterCan(configs)\n",
    "    model.load_state_dict(model_state)\n",
    "    model.to(device)\n",
    "    group_distributions[perform_name]=model\n",
    "t_observ_torch=[torch.tensor(time,device=device,dtype=torch.float32).unsqueeze(dim=1) for time in t_observ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute and prepare A,b matrices and time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test_unit=len(t_observ)\n",
    "As,Ss=compute_eval_matrices(group_distributions,t_observ_torch)\n",
    "test_unit_list=range(n_test_unit)\n",
    "bs = performs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose Experiment parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance-independent parameters\n",
    "n_train_unit =20 # 6\n",
    "n_paths = 20    # 10 #\n",
    "ood_coef=1.\n",
    "conserv_pred=0.5\n",
    "\n",
    "\n",
    "# Performance-dependent parameters\n",
    "gamma={key:perform['default_gamma'] for key,perform in performs_info.items()}\n",
    "max_life =time_info['max_life']\n",
    "\n",
    "\n",
    "# Visualization\n",
    "accel=15*3600\n",
    "time_unit=time_info['time_unit']\n",
    "long_life=max([len(time) for time in t_observ])\n",
    "t = np.linspace(0, int(long_life+5), int((long_life+5)*2.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config={'n_train_unit':n_train_unit,\n",
    "        'n_paths':n_paths,\n",
    "        'ood_coef':ood_coef,\n",
    "        'conserv_pred':conserv_pred,\n",
    "        'gamma':gamma,\n",
    "        'max_life':max_life}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_lim_={'HI': (0,1)}\n",
    "# loc_={'HI': 'lower left'}\n",
    "# monot_={'HI':'-'}\n",
    "\n",
    "# time_unit='cycle'\n",
    "# causes_text = ['HPT_eff']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = date.today()\n",
    "threshold_text=0 if not threshold_name else threshold_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp=f'threshold{threshold_text}_{today}/'\n",
    "\n",
    "exp='try'\n",
    "\n",
    "if exp == 'try':\n",
    "    n_train_unit =5 #5#\n",
    "    n_paths =5 #5# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save experiment configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_address=library_address+f'_Experiments/{exp}/'\n",
    "os.makedirs(exp_address, exist_ok=True)\n",
    "with open(exp_address+'config.pth', \"wb\") as f:\n",
    "    dump(config, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup Method\n",
    "y_lim=get_from(performs_info,'y_lim')\n",
    "loc=get_from(performs_info,'loc')\n",
    "monot=get_from(performs_info,'monot')\n",
    "EOL_cause_text =get_from(performs_info,'EOL_cause') \n",
    "\n",
    "subgroup_distributions={name:group_dist.get_sub_watercan(range(n_train_unit)) for name,group_dist in group_distributions.items()}\n",
    "\n",
    "## Results initialization\n",
    "trues = []\n",
    "pred_names='acc','csv','pred','unc'\n",
    "RMSEs={key: [] for key in pred_names}\n",
    "predss={key: [] for key in pred_names}\n",
    "causess={key: [] for key in pred_names}\n",
    "\n",
    "n_unit=1 if exp=='try' else n_test_unit\n",
    "for unit in range(n_unit): \n",
    "        A={}\n",
    "        S={}\n",
    "        b={}\n",
    "        threshold={}\n",
    "        for name in performs_info.keys():\n",
    "                A[name]= As[name][unit][:,:n_train_unit]\n",
    "                S[name]= Ss[name][unit][:,:n_train_unit]\n",
    "                b[name]= bs[name][unit]\n",
    "                thres=np.interp(t, times_thresholds[unit], thresholds[name][unit])\n",
    "                threshold[name]=torch.tensor(thres,dtype=torch.float32,device=device)\n",
    "\n",
    "        preds,causes=make_rul_video(unit,t,t_observ[unit],rul[unit],EOLcause[unit],\n",
    "                                monot, threshold, subgroup_distributions, A, b, S, gamma, y_lim, loc,\n",
    "                                perform_names=performs_info.keys(),causes_text=EOL_cause_text,time_unit=time_unit,\n",
    "                                n_train_unit=n_train_unit, n_paths=n_paths, ood_coef=ood_coef,max_life = max_life,\n",
    "                                accel=accel//3600, save=exp_address,conserv=conserv_pred)\n",
    "        y_true=rul[unit]\n",
    "\n",
    "        for name in pred_names:\n",
    "                RMSE=np.sqrt(np.mean((preds[name]-y_true)**2))\n",
    "                print(f\"RMSE_{name}: {RMSE}\")\n",
    "                RMSEs[name].append(RMSE)\n",
    "                predss[name].append(preds[name])\n",
    "                causess[name].append(causes[name])\n",
    "        trues.append(y_true)\n",
    "\n",
    "torch.save(predss,f'{exp_address}'+'preds.pt')\n",
    "torch.save(causess,f'{exp_address}'+'causes.pt')\n",
    "torch.save(trues,f'{exp_address}'+'trues.pt')\n",
    "print('----------------------------------------------------------------')\n",
    "for name in pred_names:\n",
    "        print(f\"RMSE_{name} mean: {np.mean(RMSEs[name],axis=0)}\")\n",
    "        print(f\"RMSE_{name} std: {np.std(RMSEs[name],axis=0)}\")\n",
    "print('----------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predss=torch.load(f'{exp_address}/preds.pt')\n",
    "trues=torch.load(f'{exp_address}/trues.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------- acc RMSE -------------------------------\n",
      "unit 0: 10.2939106256353\n",
      "----------------------------------\n",
      "RMSE_acc mean: 10.2939106256353\n",
      "RMSE_acc std: 0.0\n",
      "----------------------------------\n",
      "------------------------------- csv RMSE -------------------------------\n",
      "unit 0: 3.1047353156373045\n",
      "----------------------------------\n",
      "RMSE_csv mean: 3.1047353156373045\n",
      "RMSE_csv std: 0.0\n",
      "----------------------------------\n",
      "------------------------------- pred RMSE -------------------------------\n",
      "unit 0: 3.699746887608005\n",
      "----------------------------------\n",
      "RMSE_pred mean: 3.699746887608005\n",
      "RMSE_pred std: 0.0\n",
      "----------------------------------\n",
      "------------------------------- unc RMSE -------------------------------\n",
      "unit 0: 35.30232015421118\n",
      "----------------------------------\n",
      "RMSE_unc mean: 35.30232015421118\n",
      "RMSE_unc std: 0.0\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "for name in pred_names:\n",
    "        print(f'------------------------------- {name} RMSE -------------------------------')\n",
    "        RMSEs=[]\n",
    "        for unit in range(len(trues)):\n",
    "                RMSE=np.sqrt(np.mean((predss[name][unit]-trues[unit])**2))\n",
    "                print(f\"unit {unit}: {RMSE}\")\n",
    "                RMSEs.append(RMSE)\n",
    "        print('----------------------------------')\n",
    "        print(f\"RMSE_{name} mean: {np.mean(RMSEs,axis=0)}\")\n",
    "        print(f\"RMSE_{name} std: {np.std(RMSEs,axis=0)}\")\n",
    "        print('----------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./Library/MTL_2024-08-17_uav_data/_Experiments/try/'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "abel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
